import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
import joblib
import os

# --- Step 4: Model Building ---

final_features_data_path = 'data/final_features.csv'

try:
    df_final = pd.read_csv(final_features_data_path)
    print(f"Final features dataset '{final_features_data_path}' loaded for Model Building.")
except FileNotFoundError:
    print(f"Error: '{final_features_data_path}' not found.")
    print("Please ensure your final features file is generated by '02_feature_engineering.py' and is in the 'data/' directory.")
    exit()

# Define features (X) and target (y)
X = df_final.drop('Churn', axis=1)
y = df_final['Churn']

print("\nFeatures (X) shape:", X.shape)
print("Target (y) shape:", y.shape)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print(f"\nX_train shape: {X_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"y_test shape: {y_test.shape}")

# Feature Scaling
scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)
X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)

print("\nFeatures scaled using StandardScaler.")
print("X_train_scaled_df head:")
print(X_train_scaled_df.head())

# Handle Class Imbalance (SMOTE)
print("\n--- Handling Class Imbalance (SMOTE) ---")
print("Original y_train distribution:")
print(y_train.value_counts())

smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled_df, y_train)

print("\nResampled y_train distribution (SMOTE):")
print(y_train_resampled.value_counts())
print(f"X_train_resampled shape: {X_train_resampled.shape}")

# Model Training
print("\n--- Model Training ---")

lr_model = LogisticRegression(random_state=42, solver='liblinear')
lr_model.fit(X_train_resampled, y_train_resampled)
print("\nLogistic Regression Model Trained.")

rf_model = RandomForestClassifier(random_state=42, n_estimators=100)
rf_model.fit(X_train_resampled, y_train_resampled)
print("Random Forest Classifier Model Trained.")

gb_model = GradientBoostingClassifier(random_state=42, n_estimators=100, learning_rate=0.1)
gb_model.fit(X_train_resampled, y_train_resampled)
print("Gradient Boosting Classifier Model Trained.")

svc_model = SVC(random_state=42, probability=True)
svc_model.fit(X_train_resampled, y_train_resampled)
print("Support Vector Machine Model Trained.")

print("\nAll selected models trained successfully.")

# Save Trained Models
model_dir = 'models/'
if not os.path.exists(model_dir):
    os.makedirs(model_dir)
    print(f"\nCreated directory: {model_dir}")

joblib.dump(lr_model, os.path.join(model_dir, 'logistic_regression_model.pkl'))
joblib.dump(rf_model, os.path.join(model_dir, 'random_forest_model.pkl'))
joblib.dump(gb_model, os.path.join(model_dir, 'gradient_boosting_model.pkl'))
joblib.dump(svc_model, os.path.join(model_dir, 'svc_model.pkl'))
joblib.dump(scaler, os.path.join(model_dir, 'scaler.pkl')) # Save the scaler as well

print("\nAll trained models and scaler saved successfully to the 'models/' directory.")