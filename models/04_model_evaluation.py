import pandas as pd
import numpy as np
import joblib
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
import os

sns.set_style("whitegrid")

# --- Step 5: Evaluation ---

final_features_data_path = 'data/final_features.csv'

try:
    df_final = pd.read_csv(final_features_data_path)
    print(f"Final features dataset '{final_features_data_path}' loaded for Evaluation.")
except FileNotFoundError:
    print(f"Error: '{final_features_data_path}' not found.")
    print("Please ensure the file is generated by '02_feature_engineering.py' and is in the 'data/' directory.")
    exit()

X = df_final.drop('Churn', axis=1)
y = df_final['Churn']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Load the saved scaler and transform X_test
try:
    scaler = joblib.load('models/scaler.pkl')
    X_test_scaled = scaler.transform(X_test)
    X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)
    print("\nScaler loaded and X_test scaled.")
except FileNotFoundError:
    print("Error: 'scaler.pkl' not found in 'models/' directory. Cannot scale X_test properly.")
    print("Please ensure '03_model_building.py' was run to save the scaler.")
    exit()


# Load the trained models
try:
    lr_model = joblib.load('models/logistic_regression_model.pkl')
    rf_model = joblib.load('models/random_forest_model.pkl')
    gb_model = joblib.load('models/gradient_boosting_model.pkl')
    svc_model = joblib.load('models/svc_model.pkl')
    print("\nTrained models loaded successfully.")
except FileNotFoundError:
    print("Error: Models not found in 'models/' directory.")
    print("Please ensure you saved your models after training in '03_model_building.py'.")
    exit()

models = {
    'Logistic Regression': lr_model,
    'Random Forest': rf_model,
    'Gradient Boosting': gb_model,
    'SVC': svc_model
}

metrics_results = {}

print("\n--- Model Evaluation ---")

for name, model in models.items():
    print(f"\nEvaluating {name}:")
    y_pred = model.predict(X_test_scaled_df)
    y_proba = model.predict_proba(X_test_scaled_df)[:, 1]

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_proba)

    metrics_results[name] = {
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1-Score': f1,
        'ROC-AUC': roc_auc
    }

    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-Score: {f1:.4f}")
    print(f"ROC-AUC: {roc_auc:.4f}")

    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))

    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Predicted No Churn', 'Predicted Churn'],
                yticklabels=['Actual No Churn', 'Actual Churn'])
    plt.title(f'Confusion Matrix for {name}')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

    fpr, tpr, thresholds = roc_curve(y_test, y_proba)
    plt.figure(figsize=(6, 5))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'Receiver Operating Characteristic (ROC) Curve for {name}')
    plt.legend(loc="lower right")
    plt.show()

print("\n--- Summary of Model Performance ---")
metrics_df = pd.DataFrame(metrics_results).T
print(metrics_df.round(4))